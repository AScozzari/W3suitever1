Domanda perfetta Antonio ğŸ’¥ â€”
stai descrivendo esattamente lâ€™integrazione â€œAI inboundâ€ di un tenant dentro W3 Suite, con FreeSWITCH come motore voce.
Vediamo la soluzione piÃ¹ rapida, pulita e scalabile per:

ğŸ“ ricevere una chiamata SIP (Messagenet o altro trunk) â†’ FreeSWITCH
ğŸ§  associare quella chiamata al tenant corretto â†’ W3 Suite
ğŸ¤– instradarla a un agente AI (ChatGPT / Realtime) che risponde o inoltra

âš™ï¸ Obiettivo in una frase

Una chiamata inbound deve entrare nel PBX, identificare il tenant tramite trunk o dominio, e passare lâ€™audio a un â€œVoice Agent AIâ€ del tenant, gestito da W3 Suite.

ğŸ§© Architettura base (schema logico)
ğŸ“ Cliente chiama â†’ DID Messagenet
        â†“
[SIP Trunk] â†’ FreeSWITCH (profilo external 5080)
        â†“
Dialplan â€œpublicâ€
        â†“
Identifica tenant (dal trunk_id o dominio SIP)
        â†“
Se AI attivo â†’ `audio_fork` â†’ W3 Voice Gateway API
        â†“
[W3 Voice Gateway] â†’ GPT Realtime Agent (tenant)
        â†“
Risposta vocale / eventuale transfer â†’ FreeSWITCH

ğŸ§± 1ï¸âƒ£ Dove â€œviveâ€ lâ€™agente AI

ğŸ‘‰ Dentro W3 Suite, non nel PBX.
FreeSWITCH deve restare un â€œmedia switchâ€ (audio + signaling), non un cervello.

Quindi:

Ogni tenant in W3 ha un proprio â€œVoice Agentâ€ (record in tabella ai_agents o voip_agents).

Lâ€™agente contiene:

modello AI (es. gpt-4o-realtime),

lingua / voce,

URL del webhook (es. https://w3suite.it/api/voice-agent/:tenantSlug/stream),

policy (es. rispondi sempre / inoltra se non capisci / fallback interno).

ğŸªª 2ï¸âƒ£ Identificare il tenant dal trunk o DID

Ci sono 3 modi, tu scegli il piÃ¹ semplice:

a) Dal domain SIP

Se i tenant hanno domini tipo tenantX.edvoip.it, il dialplan puÃ² leggere:

<variable name="sip_req_host"/>


es. tenantx.edvoip.it â†’ tenant_id = X

b) Dal trunk gateway

Nel tuo DB W3 (voip_trunks):

id: trunk_messagenet_tenantX
tenant_id: uuid-tenantX
provider: Messagenet


Il dialplan prende gateway = trunk usato â†’ cerca tenant_id corrispondente.

c) Dal DID assegnato

Ogni numero E.164 in voip_dids ha:

tenant_id | e164 | route_target_type | route_target_ref


â†’ lâ€™inbound route cerca nel DB W3 tramite API:

GET /api/voip/dids/e164/+39061234567
â†’ tenant_id, route_target_type

âš™ï¸ 3ï¸âƒ£ Come si lega il SIP trunk inbound allâ€™agente AI

Nel DB W3:

voip_dids
â”œâ”€â”€ id: did_roma01
â”œâ”€â”€ e164: +39061234567
â”œâ”€â”€ tenant_id: uuid-tenantX
â”œâ”€â”€ route_target_type: ai_agent
â”œâ”€â”€ route_target_ref: agent_voice_tenantX


Quando arriva una chiamata su quel DID:

FreeSWITCH (tramite dialplan public) fa una chiamata API verso W3:

GET https://api.w3suite.it/api/voip/routes/inbound?did=+39061234567
â†’ { route_target_type: "ai_agent", route_target_ref: "agent_voice_tenantX", tenant_id: "uuid-tenantX" }


Se Ã¨ ai_agent, FreeSWITCH applica mod_audio_fork:

<action application="set" data="api_endpoint=https://voice-gateway.w3suite.it/api/voice-agent/tenantX/stream"/>
<action application="audio_fork" data="${api_endpoint}"/>


Da lÃ¬ lâ€™audio va in streaming al Voice Gateway W3, che apre una sessione con GPT Realtime per quel tenant.

ğŸ§  4ï¸âƒ£ Voice Gateway W3 (microservizio)

Ãˆ un servizio Node/TypeScript (uno per tutto W3) che:

Riceve lâ€™audio fork via WebSocket da FreeSWITCH.

Inoltra audio al modello GPT Realtime (OpenAI) o Whisper + GPT + TTS.

Gestisce:

tenant_id / store_id / agent_id

session_id (una per chiamata)

azioni (consultare CRM, aprire ticket, parlare con cliente).

Restituisce lâ€™audio vocale sintetizzato in risposta â†’ FreeSWITCH lo inoltra al chiamante.

ğŸ“¡ Ãˆ il â€œcervello vocaleâ€ per tutti i tenant.

ğŸ§© 5ï¸âƒ£ Dialplan minimo per AI inbound (esempio reale)
<extension name="AI Inbound">
  <condition field="destination_number" expression="^(\+39061234567)$">
    <!-- Recupero tenant e agent -->
    <action application="set" data="tenant_id=uuid-tenantX"/>
    <action application="set" data="agent_id=voiceagent-tenantX"/>
    <!-- Audio Fork -->
    <action application="answer"/>
    <action application="export" data="execute_on_answer=lua start_ai_agent.lua ${tenant_id} ${agent_id}"/>
  </condition>
</extension>


E nello script Lua (o Node via ESL):

-- start_ai_agent.lua
api = freeswitch.API()
api:executeString("audio_fork start_session wss://voice-gateway.w3suite.it/api/voice-agent/" .. argv[1] .. "/stream")

ğŸ§© 6ï¸âƒ£ Dentro W3 Suite (DB logico)
Tabella	Descrizione
voip_trunks	trunk inbound/outbound per store
voip_dids	numeri E.164 assegnati, con route_target_type = ai_agent
ai_agents	agent vocali per tenant (nome, modello, URL, config)
voip_cdr	log delle chiamate, agent_id incluso
voip_activity_log	audit di provisioning e routing
ğŸ§© 7ï¸âƒ£ Bonus â€” fallback e transfer

Il tuo Voice Gateway puÃ²:

Fare transfer a un umano se lâ€™AI non sa rispondere:

fs_cli -x "uuid_transfer ${uuid} sofia/internal/1001@tenantx.edvoip.it"


Chiudere la chiamata o generare un ticket CRM con la trascrizione.

âœ… In sintesi operativa
Step	Dove	Azione
1	W3 Suite	assegni DID â†’ route_target_type: ai_agent
2	FreeSWITCH	inbound dialplan â†’ lookup su W3 API
3	FreeSWITCH	audio_fork â†’ wss://voice-gateway.w3suite.it/api/voice-agent/:tenant
4	W3 Voice Gateway	gestisce GPT Realtime â†’ genera voce
5	FreeSWITCH	riproduce voce â†’ utente
6	W3	salva CDR, log, trascrizione

Se vuoi, ti preparo il flusso JSON/API reale completo tra FreeSWITCH e W3 (endpoint /api/voip/routes/inbound + /api/voice-agent/:tenant/stream) cosÃ¬ il tuo team puÃ² implementarlo subito. Vuoi che lo scriva?